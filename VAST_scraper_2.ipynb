{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create webdriver instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_driver = webdriver.Firefox()\n",
    "table_driver = webdriver.Firefox()\n",
    "\n",
    "summary_driver.implicitly_wait(10)\n",
    "table_driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_protein = '35ML'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process for one seed protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_driver.get(\"https://www.ncbi.nlm.nih.gov/Structure/pdb/\" + seed_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find protein length\n",
    "rulers = summary_driver.find_elements_by_class_name('mol-svg-ruler-text')\n",
    "query_protein_length = int(rulers[-1].get_attribute('innerHTML'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_links = summary_driver.find_elements_by_tag_name('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sequence/domain searches have URLs of this form. The first one is always the gray-box, or the entire sequence,\n",
    "# and not a single domain\n",
    "\n",
    "base_url = '{\\'animVal\\': \\'https://www.ncbi.nlm.nih.gov/Structure/vast/vastsrv.cgi?sdid=' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_search = ''\n",
    "\n",
    "for link in a_links:\n",
    "    href = link.get_attribute('href')\n",
    "    if type(href) == dict:\n",
    "        url_to_search = href['baseVal']\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to query the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_driver.get(url_to_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the protein query string\n",
    "query_protein_string = table_driver.find_element_by_id('query-id').get_attribute('data-querychain').replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change filter options at top\n",
    "redundancy_select = Select(table_driver.find_element_by_id('subset-select'))\n",
    "display_select = Select(table_driver.find_element_by_id('display-selection'))\n",
    "\n",
    "redundancy_select.select_by_visible_text('Low redundancy')\n",
    "display_select.select_by_visible_text('Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh table with new options\n",
    "refresh_table_button = table_driver.find_element_by_id('seqlist-button')\n",
    "refresh_table_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For navigating whole length of table\n",
    "pages = []\n",
    "try:\n",
    "    num_pages_menu = Select(table_driver.find_element_by_id('page-select-1'))\n",
    "    for o in num_pages_menu.options:\n",
    "        pages.append(o.txt)\n",
    "except:\n",
    "    print(\"All data on a single page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from a page of VAST\n",
    "table = table_driver.find_element_by_id('vast-table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = table.get_attribute('outerHTML')\n",
    "table_bsoup = BeautifulSoup(table_html, 'html.parser')\n",
    "rows = table_bsoup.find_all('tr')\n",
    "rows.pop(0) # First row is always the table header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "descriptions = []\n",
    "rmsds = []\n",
    "aligned_residues = [] \n",
    "seq_ids = []\n",
    "seed_proteins = []\n",
    "urls = []\n",
    "\n",
    "for r in rows:\n",
    "    row_values = r.text.strip().split('\\n')\n",
    "    # Filter conditions \n",
    "    # 1. Only 1 sequence of PDB entry (no domains)\n",
    "    # 2. Sequence identity < 90%\n",
    "    # 3. Matched residue length is at least 50% of the length of query protein\n",
    "    if len(row_values[0]) == 5 and float(row_values[5]) < 90 and int(row_values[1]) * 2 > query_protein_length:\n",
    "        names.append(row_values[0])\n",
    "        descriptions.append(row_values[6])\n",
    "        rmsds.append(row_values[4])\n",
    "        aligned_residues.append(row_values[1])\n",
    "        seq_ids.append(row_values[5])\n",
    "        seed_proteins.append(seed_protein)\n",
    "        \n",
    "        # This is the link to the same table, queried for the matched sequence (not just PDB ID)\n",
    "        urls.append('https://www.ncbi.nlm.nih.gov/Structure/vast/' + r.find_all('a')[1]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_dict = {\n",
    "    'name': names,\n",
    "    'seed_protein': seed_proteins,\n",
    "    'description': descriptions,\n",
    "    'rmsd': rmsds,\n",
    "    'aligned_residue': aligned_residues,\n",
    "    'sequence_id': seq_ids,\n",
    "    'url': urls\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(protein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test method for finding sequence within a PDB entry in summary page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = summary_driver.find_element_by_class_name('bucontent')\n",
    "data_table_bsoup = BeautifulSoup(data_table.get_attribute('outerHTML'), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_labels = data_table_bsoup.find_all('td', {'class': 'molecule-label-cell'})\n",
    "all_row_labels = []\n",
    "for row in molecule_labels:\n",
    "    row_list = []\n",
    "    icons_in_row = row.find_all('div', {'class': 'protein-table-chain-label'})\n",
    "    for i in icons_in_row:\n",
    "        row_list.append(i.text)\n",
    "    all_row_labels.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_row_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the links in the rulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler_cells = data_table_bsoup.find_all('div', {'class': 'annot-img-block floatClear'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_row_links = []\n",
    "for row in ruler_cells: # Convenient that the first g will always be the grey ruler box\n",
    "    g = row.find('g')\n",
    "    grey_ruler_link = g.find('a')\n",
    "    all_row_links.append(grey_ruler_link['xlink:href'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_row_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below function gets the proper VAST url for a protein chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed_protein_url(pdb_id: str):\n",
    "    summary_driver.get(\"https://www.ncbi.nlm.nih.gov/Structure/pdb/\" + pdb_id[:4])\n",
    "    \n",
    "    data_table = summary_driver.find_element_by_class_name('bucontent')\n",
    "    data_table_bsoup = BeautifulSoup(data_table.get_attribute('outerHTML'), 'html.parser')\n",
    "    \n",
    "    ruler_cells = data_table_bsoup.find_all('div', {'class': 'annot-img-block floatClear'})\n",
    "    all_row_links = []\n",
    "    for row in ruler_cells: # Convenient that the first g will always be the grey ruler box\n",
    "        g = row.find('g')\n",
    "        grey_ruler_link = g.find('a')\n",
    "        all_row_links.append(grey_ruler_link['xlink:href'])\n",
    "    \n",
    "    # Conditionals for if we are given chain ids or not\n",
    "    if len(pdb_id) == 4:\n",
    "        return all_row_links[0] # return first and only grey ruler link\n",
    "    elif len(pdb_id) == 5:\n",
    "        # Find which row should be returned - we match the chain id to the row\n",
    "        molecule_labels = data_table_bsoup.find_all('td', {'class': 'molecule-label-cell'})\n",
    "        all_row_labels = []\n",
    "        for row in molecule_labels:\n",
    "            row_list = []\n",
    "            icons_in_row = row.find_all('div', {'class': 'protein-table-chain-label'})\n",
    "            for i in icons_in_row:\n",
    "                row_list.append(i.text)\n",
    "            all_row_labels.append(row_list)\n",
    "            \n",
    "        for index, label_list in enumerate(all_row_labels):\n",
    "            if pdb_id[4] in label_list:\n",
    "                return all_row_links[index]\n",
    "        \n",
    "        return(\"ERROR - unable to find chain ID\")\n",
    "    else:\n",
    "        return(\"ERROR - invalid PDB ID length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to put it all together into a single loopable process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_from_url(url: str, known_urls: list, unknown_urls: list, aligned_threshold=0.5):\n",
    "    table_driver.get(url)\n",
    "    \n",
    "    names = []\n",
    "    descriptions = []\n",
    "    rmsds = []\n",
    "    aligned_residues = [] \n",
    "    seed_protein_total_residues = []\n",
    "    seq_ids = []\n",
    "    seed_proteins = []\n",
    "    urls = []\n",
    "    \n",
    "    try:\n",
    "        # Get the protein query string\n",
    "        query_protein_string = table_driver.find_element_by_id('query-id').get_attribute('data-querychain').replace('_', '')\n",
    "    except:\n",
    "        return names, descriptions, rmsds, aligned_residues, seed_protein_total_residues, seq_ids, seed_proteins, urls\n",
    "    \n",
    "    # Get the protein length of queried sequence\n",
    "    rulers = []\n",
    "    while not rulers:\n",
    "        rulers = table_driver.find_elements_by_class_name('svg-mol-ruler-text')\n",
    "        if rulers:\n",
    "            query_protein_length = int(rulers[-1].get_attribute('innerHTML'))\n",
    "\n",
    "    # Change filter options at top\n",
    "    redundancy_select = Select(table_driver.find_element_by_id('subset-select'))\n",
    "    display_select = Select(table_driver.find_element_by_id('display-selection'))\n",
    "    redundancy_select.select_by_visible_text('Medium redundancy')\n",
    "    display_select.select_by_visible_text('Table')\n",
    "    \n",
    "    # Refresh table with new options\n",
    "    refresh_table_button = table_driver.find_element_by_id('seqlist-button')\n",
    "    refresh_table_button.click()\n",
    "    \n",
    "    # For navigating whole length of table\n",
    "    pages = []      \n",
    "    try:\n",
    "        num_pages_menu = WebDriverWait(table_driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"page-select-1\"))\n",
    "        )\n",
    "        \n",
    "        num_pages_menu_sel = Select(num_pages_menu)\n",
    "        for o in num_pages_menu_sel.options:\n",
    "            pages.append(o.text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Case 1: Only 1 page\n",
    "    if not pages:\n",
    "        # Extract the data from a page of VAST\n",
    "        table = table_driver.find_element_by_id('vast-table')\n",
    "        table_html = table.get_attribute('outerHTML')\n",
    "        table_bsoup = BeautifulSoup(table_html, 'html.parser')\n",
    "        rows = table_bsoup.find_all('tr')\n",
    "        rows.pop(0) # First row is always the table header\n",
    "        \n",
    "        for r in rows:\n",
    "            row_values = r.text.strip().split('\\n')\n",
    "            r_url = 'https://www.ncbi.nlm.nih.gov/Structure/vast/' + r.find_all('a')[1]['href']\n",
    "            \n",
    "            # Filter conditions \n",
    "            ## 1. Only 1 sequence of PDB entry (no domains)\n",
    "            ## 2. URL isn't in known or unknown urls (we've seen or are going to see the page)\n",
    "            ## 3. Sequence identity < 90%\n",
    "            ## 4. Matched residue length is at least 50% of the length of query protein\n",
    "            \n",
    "            if (len(row_values[0]) == 5 and float(row_values[5]) <= 90 and \n",
    "                    float(row_values[1]) > query_protein_length * aligned_threshold and\n",
    "                    r_url not in known_urls and r_url not in unknown_urls):\n",
    "                names.append(row_values[0])\n",
    "                descriptions.append(row_values[6])\n",
    "                rmsds.append(row_values[4])\n",
    "                aligned_residues.append(row_values[1])\n",
    "                seed_protein_total_residues.append(query_protein_length)\n",
    "                seq_ids.append(row_values[5])\n",
    "                seed_proteins.append(query_protein_string)\n",
    "\n",
    "                # This is the link to the same table, queried for the matched sequence (not just PDB ID)\n",
    "                urls.append(r_url)\n",
    "    else:\n",
    "        # Case 2:Have to iterate through all pages of the table\n",
    "        for option in pages:\n",
    "            num_pages_menu = WebDriverWait(table_driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"page-select-1\"))\n",
    "            )\n",
    "            num_pages_menu_sel = Select(num_pages_menu)\n",
    "            num_pages_menu_sel.select_by_visible_text(option)\n",
    "            \n",
    "            # Extract the data from a page of VAST\n",
    "            table = table_driver.find_element_by_id('vast-table')\n",
    "            table_html = table.get_attribute('outerHTML')\n",
    "            table_bsoup = BeautifulSoup(table_html, 'html.parser')\n",
    "            rows = table_bsoup.find_all('tr')\n",
    "            rows.pop(0) # First row is always the table header\n",
    "\n",
    "            for r in rows:\n",
    "                row_values = r.text.strip().split('\\n')\n",
    "                r_url = 'https://www.ncbi.nlm.nih.gov/Structure/vast/' + r.find_all('a')[1]['href']\n",
    "\n",
    "                # Filter conditions \n",
    "                ## 1. Only 1 sequence of PDB entry (no domains)\n",
    "                ## 2. URL isn't in known or unknown urls (we've seen or are going to see the page)\n",
    "                ## 3. Sequence identity < 90%\n",
    "                ## 4. Matched residue length is at least 50% of the length of query protein\n",
    "\n",
    "                if (len(row_values[0]) == 5 and float(row_values[5]) <= 90 and \n",
    "                        float(row_values[1]) > query_protein_length * aligned_threshold and\n",
    "                        r_url not in known_urls and r_url not in unknown_urls):\n",
    "                    names.append(row_values[0])\n",
    "                    descriptions.append(row_values[6])\n",
    "                    rmsds.append(row_values[4])\n",
    "                    aligned_residues.append(row_values[1])\n",
    "                    seed_protein_total_residues.append(query_protein_length)\n",
    "                    seq_ids.append(row_values[5])\n",
    "                    seed_proteins.append(query_protein_string)\n",
    "\n",
    "                    # This is the link to the same table, queried for the matched sequence (not just PDB ID)\n",
    "                    urls.append(r_url)\n",
    "        \n",
    "    return names, descriptions, rmsds, aligned_residues, seed_protein_total_residues, seq_ids, seed_proteins, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_matching_proteins(pdb_id: str, known_urls: list):\n",
    "    unknown_urls = []\n",
    "    \n",
    "    names = []\n",
    "    descriptions = []\n",
    "    rmsds = []\n",
    "    aligned_residues = [] \n",
    "    seed_protein_total_residues = []\n",
    "    seq_ids = []\n",
    "    seed_proteins = []\n",
    "    \n",
    "    rejected_protein_count = 0\n",
    "    count = 0\n",
    "    \n",
    "    known_urls_new = known_urls.copy()\n",
    "    \n",
    "    # initialize our unknown_urls list\n",
    "    unknown_urls.append(get_seed_protein_url(pdb_id))\n",
    "        \n",
    "                \n",
    "    while unknown_urls: # while unknown proteins is not empty\n",
    "        current_url = unknown_urls.pop(0).strip()\n",
    "        \n",
    "        if current_url not in known_urls_new:\n",
    "            known_urls_new.append(current_url)\n",
    "            \n",
    "            threshold = 0.35 if (count == 0) else 0.80 # First round is more forgiving in protein alignment length\n",
    "            names_1, descriptions_1, rmsds_1, aligned_residues_1, seed_protein_total_residues_1, seq_ids_1, seed_proteins_1, urls_1 = \\\n",
    "                get_info_from_url(current_url, known_urls_new, unknown_urls, threshold)\n",
    "            \n",
    "            names.extend(names_1)\n",
    "            descriptions.extend(descriptions_1)\n",
    "            rmsds.extend(rmsds_1)\n",
    "            aligned_residues.extend(aligned_residues_1)\n",
    "            seed_protein_total_residues.extend(seed_protein_total_residues_1)\n",
    "            seq_ids.extend(seq_ids_1)\n",
    "            seed_proteins.extend(seed_proteins_1)\n",
    "            \n",
    "            if urls_1: #  count == 0\n",
    "                unknown_urls.extend(urls_1) # only do 1 round of neighbor of neighbor search\n",
    "            \n",
    "        count += 1\n",
    "            \n",
    "    print(\"Queried protein count for \" + pdb_id + \": \" + str(count))\n",
    "    protein_dict = {\n",
    "        'name': names,\n",
    "        'seed_protein': seed_proteins,\n",
    "        'description': descriptions,\n",
    "        'rmsd': rmsds,\n",
    "        'aligned_residue': aligned_residues,\n",
    "        'seed_protein_total_residues': seed_protein_total_residues,\n",
    "        'sequence_id': seq_ids,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(protein_dict)\n",
    "\n",
    "    return df, known_urls_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queried protein count for 1BRAA: 109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df, known_urls = get_all_matching_proteins('1L1NA', [])\n",
    "# df_2, known_urls_2 = get_all_matching_proteins('1LVMA', [])\n",
    "# df_3, known_urls_3 = get_all_matching_proteins('1WQSA', [])\n",
    "df_4, known_urls_4 = get_all_matching_proteins('1BRAA', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check difference between two protein neighbor sets\n",
    "def list_diff(list1, list2): \n",
    "    return (list(list(set(list1)-set(list2)) + list(set(list2)-set(list1)))) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of result set for 1L1NA: 111\n",
      "Length of result set for 1LVMA: 95\n",
      "Length of result set for 1WQSA: 99\n",
      "Length of result set for 1BRAA: 108\n"
     ]
    }
   ],
   "source": [
    "print('Length of result set for 1L1NA: ' + str(len(df['name'].tolist())))\n",
    "print('Length of result set for 1LVMA: ' + str(len(df_2['name'].tolist())))\n",
    "print('Length of result set for 1WQSA: ' + str(len(df_3['name'].tolist())))\n",
    "print('Length of result set for 1BRAA: ' + str(len(df_4['name'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different proteins in 1l1NA/1LVMA: 26\n",
      "Different proteins in 1l1NA/1WQSA: 28\n",
      "Different proteins in 1l1NA/1BRAA: 27\n",
      "Different proteins in 1LVMA/1WQSA: 20\n",
      "Different proteins in 1LVMA/1BRAA: 25\n",
      "Different proteins in 1WQSA/1BRAA: 29\n"
     ]
    }
   ],
   "source": [
    "print('Different proteins in 1l1NA/1LVMA: ' + str(len(list_diff(df['name'].tolist(), df_2['name'].tolist()))))\n",
    "print('Different proteins in 1l1NA/1WQSA: ' + str(len(list_diff(df['name'].tolist(), df_3['name'].tolist()))))\n",
    "print('Different proteins in 1l1NA/1BRAA: ' + str(len(list_diff(df['name'].tolist(), df_4['name'].tolist()))))\n",
    "print('Different proteins in 1LVMA/1WQSA: ' + str(len(list_diff(df_2['name'].tolist(), df_3['name'].tolist()))))\n",
    "print('Different proteins in 1LVMA/1BRAA: ' + str(len(list_diff(df_2['name'].tolist(), df_4['name'].tolist()))))\n",
    "print('Different proteins in 1WQSA/1BRAA: ' + str(len(list_diff(df_3['name'].tolist(), df_4['name'].tolist()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['name'].tolist() + df_2['name'].tolist() + df_3['name'].tolist() + df_4['name'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seed_protein</th>\n",
       "      <th>description</th>\n",
       "      <th>rmsd</th>\n",
       "      <th>aligned_residue</th>\n",
       "      <th>seed_protein_total_residues</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4CBNA</td>\n",
       "      <td>4JCNA</td>\n",
       "      <td>Crystal Structure Of Complement Factor D Mutan...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>177</td>\n",
       "      <td>216</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4IBLH</td>\n",
       "      <td>4JCNA</td>\n",
       "      <td>Rubidium Sites In Blood Coagulation Factor Viia</td>\n",
       "      <td>2.2</td>\n",
       "      <td>176</td>\n",
       "      <td>216</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>4M7GA</td>\n",
       "      <td>4JCNA</td>\n",
       "      <td>Streptomyces Erythraeus Trypsin</td>\n",
       "      <td>2.2</td>\n",
       "      <td>173</td>\n",
       "      <td>216</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3FANA</td>\n",
       "      <td>1MBMA</td>\n",
       "      <td>Crystal Structure Of Chymotrypsin-Like Proteas...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>173</td>\n",
       "      <td>198</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3QO6B</td>\n",
       "      <td>2WV5D</td>\n",
       "      <td>Crystal Structure Analysis Of The Plant Protea...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>175</td>\n",
       "      <td>214</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name seed_protein                                        description  \\\n",
       "90  4CBNA        4JCNA  Crystal Structure Of Complement Factor D Mutan...   \n",
       "91  4IBLH        4JCNA    Rubidium Sites In Blood Coagulation Factor Viia   \n",
       "92  4M7GA        4JCNA                    Streptomyces Erythraeus Trypsin   \n",
       "93  3FANA        1MBMA  Crystal Structure Of Chymotrypsin-Like Proteas...   \n",
       "94  3QO6B        2WV5D  Crystal Structure Analysis Of The Plant Protea...   \n",
       "\n",
       "   rmsd aligned_residue  seed_protein_total_residues sequence_id  \n",
       "90  2.2             177                          216        14.7  \n",
       "91  2.2             176                          216        12.5  \n",
       "92  2.2             173                          216        15.0  \n",
       "93  3.1             173                          198        35.3  \n",
       "94  2.9             175                          214        13.1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./dataset_2/1L1N_med.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to repeat above process for multiple seed proteins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_proteins = {\n",
    "#     'C03': ['1L1NA', '1HAVA', '1CQQA', '2J92A', '2ZU3A', '2HRVA'],\n",
    "#     'C04': ['1LVM'],\n",
    "#     'C37': ['1WQSA'],\n",
    "#     'S01': ['2GMT', '1IAU', '1A0L', '2PSY', '2OQ5', '1OP0A', '2F91B', '1FI8A',\n",
    "#             '1BRA', '1SGT', '1TRY', '2W5EA', '1DPO', \n",
    "#             '1HYL', '1AZZA', '1A0J',\n",
    "#             '1TRN', '1HNE', '1CGH', '1FUJ', '1ORF', '1ORF', '3FZZ', \n",
    "#             '2ZGCA', '3RP2', '2F9P', '1MZA', '2RDLA', '1JRS', '2JETA', '1ELC', '1EKB', \n",
    "#             '1PYTC', '3DFJ', '2ZCHP', '1SGFG', '1GVZ', '1TON', '1AO5', \n",
    "#             '2R9PC', \n",
    "#             '1MD7A', '1ELV', '2ODP', '3GOVA', '2OLG', '1ZJDA', '1PFX', '1DAN',\n",
    "#             '1HCG', '1ABJ', '1AUT', '1FIZ', '1O5FL', '1YBW', '1Q3X', '1MLW',\n",
    "#             '1BUIA', '1LO6A', '1YM0', \n",
    "#             '1NPM', '2BDGA', '1SGC', '1SGPE', \n",
    "#             '1HPG', '2ALP', '1QY6', '1EXF', '1KY9A', '1SO7', '1LCYA', \n",
    "    'S01': ['1ARC',\n",
    "            '2VID', '2AS9A', '2QXIA', '2GV6A', '2SFA', '1EQ9', '1P3E', \n",
    "            '2AIQA', '1L1J', '2XXL', '1SGFA', '2PFE'\n",
    "           ],\n",
    "    'S03': ['2SNV'],\n",
    "    'S06': ['1WXR'],\n",
    "    'S29': ['1A1R'],\n",
    "    'S32': ['1MBMA'],\n",
    "    'S39': ['1ZYO']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queried protein count for 1ARC: 1\n",
      "Queried protein count for 2VID: 3\n",
      "Queried protein count for 2AS9A: 1\n",
      "Queried protein count for 2QXIA: 1\n",
      "Queried protein count for 2GV6A: 2\n",
      "Queried protein count for 2SFA: 2\n",
      "Queried protein count for 1EQ9: 1\n",
      "Queried protein count for 1P3E: 1\n",
      "Queried protein count for 2AIQA: 1\n",
      "Queried protein count for 1L1J: 1\n",
      "Queried protein count for 2XXL: 1\n",
      "Queried protein count for 1SGFA: 1\n",
      "Queried protein count for 2PFE: 4\n",
      "Queried protein count for 2SNV: 1\n",
      "Queried protein count for 1WXR: 2\n",
      "Queried protein count for 1A1R: 3\n",
      "Queried protein count for 1MBMA: 1\n",
      "Queried protein count for 1ZYO: 1\n"
     ]
    }
   ],
   "source": [
    "for family, pdb_list in pa_proteins.items():\n",
    "    for p in pdb_list:\n",
    "        with open('dataset_2/known_proteins.txt', 'r+') as known_proteins_file:\n",
    "            known_proteins = known_proteins_file.read().splitlines()\n",
    "\n",
    "            df, new_known_proteins = get_all_matching_proteins(p, known_proteins)\n",
    "\n",
    "            # known_proteins.extend(new_known_proteins)\n",
    "\n",
    "            # Write out new data\n",
    "            outdir = './dataset_2/' + family\n",
    "            if not os.path.exists(outdir):\n",
    "                os.mkdir(outdir)\n",
    "\n",
    "            df.to_csv('./dataset_2/' + family + '/' + p + '.csv')\n",
    "\n",
    "            known_proteins_file.seek(0)\n",
    "            known_proteins_file.writelines(s + '\\n' for s in new_known_proteins)\n",
    "            known_proteins_file.truncate()\n",
    "\n",
    "\n",
    "            del new_known_proteins[:]\n",
    "            del known_proteins\n",
    "            del df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1L1N_med.csv',\n",
       " 'C03',\n",
       " 'C04',\n",
       " 'C37',\n",
       " 'known_proteins.txt.txt',\n",
       " 'S01',\n",
       " 'S03',\n",
       " 'S06',\n",
       " 'S29',\n",
       " 'S32',\n",
       " 'S39']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
